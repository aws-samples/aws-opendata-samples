{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a86d38",
   "metadata": {},
   "source": [
    "# Accessing AWS Open Data Using Boto3\n",
    "This notebook demonstrates how to access public datasets in the AWS Open Data program using the Boto3 SDK in Python. We'll use the `human-pangenomics` dataset as an example and explore how to list contents, navigate folders, and download files programmatically.\n",
    "\n",
    "This notebook is designed to run in **Amazon SageMaker Studio**. You can also run it in [SageMaker Studio Lab](https://studiolab.sagemaker.aws/) if you don't have an AWS account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a729b44",
   "metadata": {},
   "source": [
    "## List Top-Level Contents of the Bucket\n",
    "When working with AWS Open Data, one of the first tasks is to browse the contents of an S3 bucket. Similar to using the AWS CLI to list bucket contents, you can achieve the same functionality using Boto3. The following example retrieves and lists only the top-level directories and files within a bucket using the list_objects_v2 method with the Delimiter='/' parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f1415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "bucket_name = \"human-pangenomics\"\n",
    "\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Delimiter='/')\n",
    "\n",
    "if 'CommonPrefixes' in response:\n",
    "    for prefix in response['CommonPrefixes']:\n",
    "        print(prefix['Prefix'])\n",
    "\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        print(obj['Key'])\n",
    "else:\n",
    "    print(\"No objects found in the bucket.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c4c728",
   "metadata": {},
   "source": [
    "## Navigate to a Specific Folder\n",
    "Once inside an S3 bucket, you may want to explore a specific folder to locate the files you need. By specifying a folder prefix in the request, Boto3 allows you to narrow down the results to a particular directory within the bucket. This approach mirrors the AWS CLI's ability to list contents within a folder. Let's explore the contents of the `pangenomes/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9595bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_prefix = \"pangenomes/\"\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Prefix=folder_prefix, Delimiter='/')\n",
    "\n",
    "if 'CommonPrefixes' in response:\n",
    "    for prefix in response['CommonPrefixes']:\n",
    "        print(prefix['Prefix'])\n",
    "\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        print(obj['Key'])\n",
    "else:\n",
    "    print(\"No objects found in the folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921521f1",
   "metadata": {},
   "source": [
    "## Download a Single File\n",
    "After identifying the required files, the next step is to download them to your local environment. Boto3 provides the download_file method to retrieve individual files from an S3 bucket, just as you would with the AWS CLI. Let's download a single README file from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afb72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key = \"pangenomes/scratch/2021_03_22_minigraph/00README.txt\"\n",
    "local_file_name = \"00README.txt\"\n",
    "s3.download_file(bucket_name, file_key, local_file_name)\n",
    "print(f\"File {local_file_name} downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b39ed3",
   "metadata": {},
   "source": [
    "## Download an Entire Folder Recursively\n",
    "In cases where you need multiple files, downloading an entire folder is often more efficient than retrieving files individually. Unlike the AWS CLI, which has a built-in --recursive flag, Boto3 requires iterating through the folder's contents and downloading each file programmatically. The example below demonstrates how to achieve this using a paginator to retrieve all objects within the `working/T2T/CHM13/paper/Nurk_2021/fig3/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a927c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def download_folder(bucket_name, folder_prefix, local_directory):\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    for page in paginator.paginate(Bucket=bucket_name, Prefix=folder_prefix):\n",
    "        for obj in page.get('Contents', []):\n",
    "            file_key = obj['Key']\n",
    "            local_path = os.path.join(local_directory, os.path.relpath(file_key, folder_prefix))\n",
    "            os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "            s3.download_file(bucket_name, file_key, local_path)\n",
    "            print(f\"Downloaded {file_key} to {local_path}\")\n",
    "\n",
    "folder_prefix = \"working/T2T/CHM13/paper/Nurk_2021/fig3/\"\n",
    "local_directory = \"./copied_folder\"\n",
    "download_folder(bucket_name, folder_prefix, local_directory)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
