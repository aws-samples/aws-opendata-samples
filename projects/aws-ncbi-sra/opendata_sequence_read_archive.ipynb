{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe226cb-a184-4720-ab43-295276ad5523",
   "metadata": {},
   "source": [
    "# Sequence Read Archive (SRA) on AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433069cb-d540-474d-98e1-90631daad856",
   "metadata": {},
   "source": [
    "## Drive New Research Discoveries by Exploring Raw DNA Sequencing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef8c45-af1e-4629-85c7-6f0fc71dc396",
   "metadata": {},
   "source": [
    "The Sequence Read Archive (SRA) data is stored on AWS as part of the Registry Open Data. The data, stored in AWS Simple Storage Service (S3) is publicly available and does not require an AWS Account to access. However in this example, we are specifying an AWS S3 Bucket to store the data in your AWS Account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bc672f-86be-4a32-b4cc-ed94f54aea26",
   "metadata": {},
   "source": [
    "### Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b0038-9be4-40ed-8c01-91787254f5e4",
   "metadata": {},
   "source": [
    "To learn more about the individual libraries being imported, please reference: https://docs.python.org/3/library/index.html/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8576c-66b1-46f1-b3b5-ae7bb0a3a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bab4ea-88e9-498d-b792-62fe8b3787d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "import collections\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18872b4f-9e02-4f41-a1e0-3ec98cef411b",
   "metadata": {},
   "source": [
    "### Define Source S3 Bucket and Destination S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb171416-809f-4ca8-862b-e233a36f473c",
   "metadata": {},
   "source": [
    "The <code>source_bucket</code> variable specifies the S3 bucket from which you will copy the Sequence Read Archive data from. The repository contains many buckets containing different data types. For the purpose of this example, you will copy data from a specific bucket. You can modify the <code>source_bucket</code> with another bucket name or keep the default below.\n",
    "\n",
    "The <code>dest_bucket</code> variable represents the S3 bucket within your AWS Account where the Sequence Read Archive data will be copied to. Before executing, update the <code>dest_bucket</code> variable below as shown with the name of the S3 Bucket you created during the CloudFormation Stack execution. If you did not use CloudFormation to prep the environment, you will need to manually create an S3 bucket and populate the name below in <code>dest_bucket</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f19a8-879f-4de1-bcf7-fdbfdb234003",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bucket = 'sra-pub-src-1'\n",
    "dest_bucket = 'enter_the_bucket_name_created_through_cloud_formation_here'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ce3ce-4256-485d-b1ac-83c75c1418c2",
   "metadata": {},
   "source": [
    "### Initialize Python Boto3 Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5ecfe6-4fd6-4a43-82b6-f9019ad7b005",
   "metadata": {},
   "source": [
    "In this example you are leveraging AWS S3 to transfer the sequencing data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4556760-0876-497a-b6a3-df09bc9b07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f6ae22-e8f0-49af-9cdf-30fcfed3b4fa",
   "metadata": {},
   "source": [
    "### Search the SRA Bucket and Copy FASTQ Files to Your Destination Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128acb8e-f90f-4877-9b27-8c7f2d30347b",
   "metadata": {},
   "source": [
    "The combination of the Python paginator feature and S3 List Objects operation allows you to search the provided <code>source_bucket</code> returning X number of objects where X is defined below as MaxItems.\n",
    "\n",
    "You can modify the MaxItems to return a larger list but note that the more files in the bucket, the longer the list will take to return. \n",
    "\n",
    "For the purpose of this lab you will choose an object with a <code>key</code> like <code>.fastq.gz.1</code> to populate into the next section for copying the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09366bc6-2b42-400e-9133-85527a590d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "page_iterator = paginator.paginate(Bucket=source_bucket,\n",
    "PaginationConfig={'MaxItems': 20})\n",
    "for page in page_iterator:\n",
    "    for obj in page['Contents']:\n",
    "        print(f's3://{source_bucket}/{obj[\"Key\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208dd251-b9a8-407f-9cce-3287884dd138",
   "metadata": {},
   "source": [
    "### Set Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0329f9c-06a4-40d7-a2ac-d893b5296387",
   "metadata": {},
   "source": [
    "Example Variables are provided below and can be used as is. Update if desired to utilize other fastq files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187389be-1fce-4481-8d31-7805fc2d5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='Sample_ApoB_Mouse_S4_L003_I1_001.fastq.gz.1'\n",
    "key='ERR10009485/Sample_ApoB_Mouse_S4_L003_I1_001.fastq.gz.1'\n",
    "prefix='ERR10009485'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb65f540-c8c1-447b-a9e4-75d26d73e0ba",
   "metadata": {},
   "source": [
    "### Copy FASTQ File from Source Bucket to Destination Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab4cc1-2d5f-4bd4-8596-c141f46fa444",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16232b6-76ff-4d92-a5d6-3a73d9e8b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_source = {\n",
    "        'Bucket': source_bucket,\n",
    "        'Key': key\n",
    "}\n",
    "s3.meta.client.copy(copy_source, dest_bucket, key)\n",
    "\n",
    "print(f\"Copied files from {source_bucket} to {dest_bucket}/{key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e60de56-095d-4809-b0f2-b59dd7e0bf59",
   "metadata": {},
   "source": [
    "### List Files of Destination Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cebbcf-e624-409f-9a06-38246eecc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff65db5-e271-45e5-91c6-d4c8f6c5964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator = s3.get_paginator('list_objects')\n",
    "operation_parameters = {'Bucket': dest_bucket,\n",
    "                        'Prefix': prefix}\n",
    "page_iterator = paginator.paginate(**operation_parameters)\n",
    "for page in page_iterator:\n",
    "    print(page['Contents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e1954-99e2-463d-b234-c93277633a5d",
   "metadata": {},
   "source": [
    "### Download FASTQ File from S3 to Sagemaker Notebook Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd11af2-e352-4334-a5e8-c191dbaf87de",
   "metadata": {},
   "source": [
    "Due to the size of the FASTQ files you will need to download them to the local SageMaker Notebook instance already created for you. The file will still be available in S3 for use until you manually delete it or remove the CloudFormation stack. It is advised to consider the OpenData version of the file as long term to reduce duplication of data and minimize resources per Sustainability best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188f31c-c803-49cc-b323-bc2ccb991c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354cb89-9460-4e11-9909-b4ed7a6c18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file( \n",
    "    Filename=filename, \n",
    "    Bucket=dest_bucket, \n",
    "    Key=key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b57aeb5-dd59-4c1f-9fb2-f3d90b5bdef9",
   "metadata": {},
   "source": [
    "### Read Nucleotide Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a422c2-e92b-4fc5-993a-1c1dd35a0598",
   "metadata": {},
   "source": [
    "Below the provided gzip-compressed FASTQ file is read, the first sequence record is extracted and information on the record is printed including the sequence data and the associated quality scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e2a30-8af8-475c-9a7f-e03b9df5e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = SeqIO.parse(gzip.open(filename, 'rt', encoding='utf-8'), 'fastq')\n",
    "record = next(records)\n",
    "print(record)\n",
    "print(record.id,record.description,record.seq)\n",
    "print(record.letter_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da46b55-c83d-4f6e-85ff-f76f7ed22f77",
   "metadata": {},
   "source": [
    "### Plot the Nucleotide Reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8feb9f-c746-4d88-887a-06c2814ba343",
   "metadata": {},
   "source": [
    "Using the `gzip` module the FASTQ file will be opened in read mode. The file is read line by line, skipping the header and quality score lines, while counting the occurences of each nucleotide (A, T, C, G) using  the `collections.Counter()` class . After counting the nucleotides, the script uses the `matplotlib.pyplot` library to generate plotar graph showing the distribution of the nucleotide 4. The `plt.figure()` function sets the size of the plot, and the `plt.bar()` function creates tplotbar graph using the nucleotide counts as the y-axis values and the nucleotides as the x-axis labe \n",
    "5. Finally, the `plt.xlabel()`, `plt.ylabel()`, and `plt.title()` functions add labels and a title to the plot, and the `plt.show()` function displays the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b366bb-dc6b-48ef-a7e3-11000523fcc0",
   "metadata": {},
   "source": [
    "### Define Function to Read Specific # of Lines of FASTQ File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81162e6-ff5e-42e3-89e3-a5c86a95395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fastq_subset(filename, start_line=0, num_lines=None):\n",
    "    \"\"\"\n",
    "    Read a subset of lines from a gzipped FASTQ file.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): The path to the gzipped FASTQ file.\n",
    "        start_line (int, optional): The starting line number to read (default is 0).\n",
    "        num_lines (int, optional): The number of lines to read (default is None, which means read all lines).\n",
    "    \n",
    "    Returns:\n",
    "        generator: A generator that yields the selected lines from the FASTQ file.\n",
    "    \"\"\"\n",
    "    with gzip.open(filename, 'rt') as f:\n",
    "        # Skip the initial lines\n",
    "        for _ in range(start_line):\n",
    "            f.readline()\n",
    "        \n",
    "        # Read the selected lines\n",
    "        if num_lines is None:\n",
    "            yield from f\n",
    "        else:\n",
    "            for _ in range(num_lines):\n",
    "                yield f.readline().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58234128-f2c1-4fdd-a41c-cddae5c0f97d",
   "metadata": {},
   "source": [
    "### Execute the Function to Plot the Nucleotide Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fae7c6-ae0d-4c2b-8589-c5f66b2473c9",
   "metadata": {},
   "source": [
    "By default, the entire FASTQ file will be read. If you want to only read a subset, modify the start_line and num_lines below, accordingly.\n\n**Note:** This cell processes the entire genomics file and may take 10-15 minutes to complete depending on file size. The cell will show [*] while running - please be patient as it counts nucleotides and generates the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89fdbef-a897-4100-bf9d-cf82ecb65295",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotide_counts = collections.Counter()\n",
    "for line in read_fastq_subset(filename, start_line=0, num_lines=None):\n",
    "        if line.startswith('@'):\n",
    "            # Skip the header line\n",
    "            continue\n",
    "        elif line.startswith('+'):\n",
    "            # Skip the quality score line\n",
    "            continue\n",
    "        else:\n",
    "            # Count the nucleotides in the sequence line\n",
    "            nucleotide_counts.update(line.strip())\n",
    "\n",
    "# Plot the distribution of nucleotides\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(nucleotide_counts.keys(), nucleotide_counts.values())\n",
    "plt.xlabel('Nucleotide')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Nucleotides')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f389387e-21e6-4caa-9a97-9dea07637644",
   "metadata": {},
   "source": [
    "### Cleanup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da86a6e-5cf3-406f-b2fa-3b7f4824cda3",
   "metadata": {},
   "source": [
    "To avoid encuring costs associated with the environment created in your account. Delete the CloudFormation Stack which will remove all created resources. Execute the cell below to delete the downloaded FASTQ file. If the S3 bucket created by CloudFormaton is not empty, the Delete step for CloudFormation will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2902f16b-1284-413d-bd06-9f4cbb99901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive cleanup for versioned S3 buckets\n",
    "def cleanup_versioned_bucket(bucket_name):\n",
    "    \"\"\"Delete all objects and versions from a versioned S3 bucket\"\"\"\n",
    "    print(f\"Starting cleanup of bucket: {bucket_name}\")\n",
    "    \n",
    "    try:\n",
    "        # First, list all current objects\n",
    "        response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "        if 'Contents' in response:\n",
    "            print(f\"Found {len(response['Contents'])} current objects\")\n",
    "            for obj in response['Contents']:\n",
    "                print(f\"  - {obj['Key']}\")\n",
    "        else:\n",
    "            print(\"No current objects found\")\n",
    "        \n",
    "        # List and delete all object versions\n",
    "        paginator = s3.get_paginator('list_object_versions')\n",
    "        pages = paginator.paginate(Bucket=bucket_name)\n",
    "        \n",
    "        delete_keys = []\n",
    "        total_versions = 0\n",
    "        total_markers = 0\n",
    "        \n",
    "        for page in pages:\n",
    "            # Delete object versions\n",
    "            if 'Versions' in page:\n",
    "                for version in page['Versions']:\n",
    "                    delete_keys.append({\n",
    "                        'Key': version['Key'], \n",
    "                        'VersionId': version['VersionId']\n",
    "                    })\n",
    "                    total_versions += 1\n",
    "            \n",
    "            # Delete delete markers\n",
    "            if 'DeleteMarkers' in page:\n",
    "                for marker in page['DeleteMarkers']:\n",
    "                    delete_keys.append({\n",
    "                        'Key': marker['Key'], \n",
    "                        'VersionId': marker['VersionId']\n",
    "                    })\n",
    "                    total_markers += 1\n",
    "        \n",
    "        print(f\"Found {total_versions} object versions and {total_markers} delete markers\")\n",
    "        \n",
    "        if delete_keys:\n",
    "            # Delete in batches of 1000 (AWS limit)\n",
    "            deleted_count = 0\n",
    "            for i in range(0, len(delete_keys), 1000):\n",
    "                batch = delete_keys[i:i+1000]\n",
    "                if batch:\n",
    "                    response = s3.delete_objects(\n",
    "                        Bucket=bucket_name,\n",
    "                        Delete={'Objects': batch}\n",
    "                    )\n",
    "                    deleted_count += len(batch)\n",
    "                    print(f\"Deleted batch of {len(batch)} objects/versions\")\n",
    "            \n",
    "            print(f\"Successfully deleted {deleted_count} total objects/versions from {bucket_name}\")\n",
    "        else:\n",
    "            print(f\"No objects or versions to delete in {bucket_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning up {bucket_name}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Clean up both buckets\n",
    "print(\"=== S3 Bucket Cleanup ===\")\n",
    "cleanup_versioned_bucket(dest_bucket)\n",
    "print()\n",
    "\n",
    "# Construct logging bucket name\n",
    "account_id = dest_bucket.split('-')[0]\n",
    "logging_bucket = f\"{account_id}-opendata-sra-logs\"\n",
    "cleanup_versioned_bucket(logging_bucket)\n",
    "\n",
    "print()\n",
    "print(\"=== Cleanup Complete ===\")\n",
    "print(\"You can now safely delete the CloudFormation stack.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
